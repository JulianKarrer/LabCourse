\chapter{Smoothed Particle Hydrodynamics}\label{chp:sph-discretization}


In \autoref{chp:governing-equations}, the governing equations of fluid flow were derived in their Lagrangian differential form for continuous field quantities. To make the simulation of fluids tractable, these equations must now be discretized in space and time so that the evolution of the system can be numerically calculated.

The temporal domain is commonly discretized into global time steps $\Delta t$ that propagate the solution of the system into the future. Numerically integrating the acceleration $\vek{a}_i(t)  = \frac{D\vek{v}_i(t)}{D t}$ from the left-hand side of the momentum equation (\autoref{eq:navier-stokes-momentum}) twice with respect to time yields a change in position $\Delta\vek{x}$ that can be used to advect quantities. Symplectic Euler time integration (also referred to as semi-implicit Euler or Euler-Cromer) is very commonly used to achieve this\autocite*{tutorial}:
\begin{align}\label{eq:symplectic-euler}
  \vek{v}_i(t+\Delta t) & = \vek{v}_i(t) + \Delta t \vek{a}_i(t)          \\
  \vek{x}_i(t+\Delta t) & = \vek{x}_i(t) + \Delta t \vek{v}_i(t+\Delta t)
\end{align}

The subscript $i$ in these equations indicates that quantities are evaluated at respective particle positions $\vek{x}_i$, which are advected with the velocity field. This is why the Lagrangian form is applicable, and the material derivative can be implemented as a total derivative with respect to time.

The spatial discretization of the problem is less straightforward and yields different methods depending on the scheme chosen.


\section{Spatial Discretization of the Continuum}
The discretization chosen here makes use of \emphasis{Smoothed Particle Hydrodynamics} or \emphasis{SPH} for short, which was devised independently by Lucy\autocite*{sph-lucy-77} as well as Gingold and Monaghan\autocite*{sph-monaghan-gingold-77} in 1977. Despite its name, this scheme has little to do with Hydrodynamics per se and does not even strictly require a particle representation of quantities to work, but rather is a general framework for the interpolation of field quantities stored at discrete locations to obtain a smooth function that can be evaluated at any location.

Since the Lagrangian framework tends to favour discretizing the continuum itself over the space it exists within, regions of the continuum are here represented by so-called particles with a singular position that represent some volume or, equivalently in the incompressible case with homogeneous density, mass. It is important to keep in mind that the word \textit{particle} in this context refers not to a physical, elementary particle or a spherical object, but rather an abstract representation of a discrete, shapeless parcel of the continuum.

SPH can be derived by considering that these particles represent a sampling of the continuous fluid domain at singular points and can be expressed as Dirac-$\delta$ distributions weighted by some quantity. The $\delta$-distribution can be defined as being normalized:
\begin{equation}
  \int \delta(\vek{x}) \,dV = 1
\end{equation}
and obeying $\vek{x}\neq \vek{0} \Longrightarrow \delta(\vek{x}) = 0$. This results in a distribution that is zero everywhere but at a singularity at the origin, where a spike of undefined height shoots up and only the integral of the distribution across that spike is a well-defined function ($\delta$ itself is a \textit{generalized function}, not one in the analytic sense\autocite*{signal-processing-falaschi}). The Dirac-$\delta$ can be thought of as the limit of a Gaussian distribution as the variance approaches zero and the distribution becomes ever higher and narrower\autocite{tutorial}.\\
For this distribution representing the particles, the identity holds that for any continuous, compactly supported function $A(\vek{x})$\autocite{tutorial}:
\begin{equation}\label{eq:conv-identity}
  A(\vek{x}) = (A * \delta)(\vek{x}) = \int A(\vek{x}') \delta(\vek{x}-\vek{x}')dV'
\end{equation}
or the convolution of $A$ with $\delta$ is $A$ itself. This identity can be explained from the perspective of Fourier analysis, where the $\delta$ can be defined as the constant unit function in Fourier space and therefore $\delta = \mathcal{F}^{-1}(1)$. Since the convolution theorem applies, it then holds that a convolution in the spatial domain is equivalent to a multiplication in the transformed domain and vice-versa, resulting in a multiplication by one in the case of the convolution with a $\delta$-distribution real space, and therefore an identity.

The key insight to SPH is that the $\delta$-distribution can be approximated by a more well-behaved function with desirable properties such as smoothness, while approximately retaining the above identity. Such a function is referred to in SPH as a \emphasis{kernel function} $W$, \textit{smoothing kernel}\autocite*{tutorial} or \textit{broadening function}\autocite*{sph-lucy-77}, since it broadens and smooths out the Dirac-$\delta$ distribution. With this, one can then derive\autocite*{tutorial}:
\begin{align}
  A(\vek{x}) & = (A * \delta)(\vek{x})                                                                             & \text{\autoref{eq:conv-identity}}                                                                       \\
             & = \int A(\vek{x}') \delta(\vek{x}-\vek{x}') dV'                                                     & \text{Def. of convolution, \textit{sifting property} of $\delta$\autocite*{signal-processing-falaschi}} \\                                                             \label{eq:sph-derivation-kernel-approx}
             & \approx \int A(\vek{x}') W(\vek{x}-\vek{x}') dV'                                                    & \text{approximate $\delta$ by $W$}                                                                      \\
             & = \int \frac{A(\vek{x}')}{\rho(\vek{x}')} W(\vek{x}-\vek{x}') \underbrace{\rho(\vek{x}')dV'}_{=dm'} & \text{multiply by $\frac{\rho(\vek{x}')}{\rho(\vek{x}')}=1$}                                            \\\label{eq:sph-derivation-sum-approx}
             & \approx \sum_{\vek{x}_j\in\mathcal{S}} A_j \frac{m_j}{\rho_j} W(\vek{x}-\vek{x}_j)                  & \text{approximate Integral with discrete samples}
\end{align}
where subscripts denote the position where a quantity is evaluated as in $A_j := A(\vek{x}_j)$ and $\mathcal{S}$ is a set of fluid samples. This leads to the general SPH approximation for any field quantity\autocite*{tutorial} $A$:
\begin{equation}\label{eq:sph-any-quantity}
  A_i = \sum_j A_j \frac{m_j}{\rho_j} W_{ij}
\end{equation}
where the sample set $\mathcal{S}$ is implicit in the notation and $W_{ij} := W(\vek{x}_i-\vek{x}_j)$. The term $\frac{m_j}{\rho_j} = V_j$ can be seen as the fluid volume that sample $j$ represents.

Note in particular that the mass density:
\begin{equation}\label{eq:density-sph}
  \rho_i = \sum_j m_j W_{ij}
\end{equation} is simply a sum over kernel functions weighted by the respective mass of samples\autocite*{tutorial}. Since mass can be perfectly conserved in a Lagrangian framework, this lends itself to fluid solvers that enforce density invariance as opposed to minimizing velocity divergence and the errors of which therefore result in volume oscillations rather than loss of volume and drift - this trade-off might be desirable but is not required by the SPH scheme in general.

As briefly mentioned before, SPH simply employs the kernel function $W$ to perform a smoothing, thereby interpolating discrete samples, and does not necessarily have to be applied only to locations that coincide with particle positions, although finding the value of field quantities at a particle position is certainly desirable in a Lagrangian fluid simulation.

Further, note that since the gradient is a linear operator it can be pulled into the sum in \autoref{eq:sph-any-quantity}, resulting in\autocite*{tutorial}:
\begin{equation}\label{eq:sph-nabla-any-quantity}
  \nabla A_i \approx \sum_j A_j \frac{m_j}{\rho_j} \nabla W_{ij}
\end{equation}
such that the gradient of a field can conveniently be computed simply by evaluating the function $\nabla W$ instead of $W$.

\newpage
\section{Kernel Functions and Properties}

So far it has been left unspecified what form exactly the kernel function $W$ takes, although some of its required properties were alluded to. Furthermore, $W$ is often parameterized in its support radius $\hbar$ and smoothing length, which we will assume to be equal in the following, yielding $W(\vek{x}_{ij}, \hbar)$, where $\vek{x}_{ij} = \vek{x}_i-\vek{x}_j$. Properties of this function shall be enumerated in the following\autocite*{tutorial}:

\begin{description}
  \item[Normalization] $\int_\mathcal{V} W(\vek{x}_{ij}, \hbar) d\vek{x}_j = 1$\\
        is required for the approximation to be consistent.
  \item[Dirac-$\boldsymbol{\delta}$ Condition] $\lim_{\hbar\rightarrow 0} W(\vek{x}_{ij}, \hbar) = \delta(\vek{x}_{ij})$ \\
        is the motivation for the scheme in the first place and required for $A=(A * \delta)=(A * W)$ to hold in the limit.
  \item[Compact Support] $\forall \dist{\vek{x}_{ij}} > \hbar: W(\vek{x}_{ij}, \hbar) = 0$\\
        reduces the SPH sum from $\mathcal{O}(n^2)$-complexity in $n$ particles to potentially $\mathcal{O}(n)$
  \item[Sufficient Smoothness] $W \in C^n, n\geq 2$\\
        it is desirable for the first few derivatives of $W$ to be continuous for discretizations such as in \autoref{eq:sph-nabla-any-quantity} to be viable and for second order partial differential equations to be handled with ease\autocite*{tutorial}
  \item[Positivity] $\forall \vek{x}_{ij}: W(\vek{x}_{ij}, \hbar) \geq 0$\\
        while negative values of the kernel are permitted\autocite*{sph-lucy-77} and even desired in some cases such as when modelling surface tension\autocite*{surface-tension-akinci-2013}, they are typically avoided since they might yield unphysical results at suboptimal sampling for quantities that should not be negative like mass, density, volume etc.
  \item[Symmetry] $W(\vek{x}_{ij}, \hbar) = W(\vek{x}_{ji}, \hbar)$\\
        is typically desired, even if just for lack of better assumptions about the structure of the interpolated field - indeed most kernels are spherically symmetric and only depend on the distance $\dist{\vek{x}_{ij}}$ between two points, which is especially valid when the interpolated field is assumed to be approximately isotropic on scales of the order of $\hbar$.
\end{description}

Note that the two required properties in this case, the normalization and $\delta$-condition, correspond to the two approximations made in \autoref{eq:sph-derivation-kernel-approx} and \autoref{eq:sph-derivation-sum-approx} of the derivation of SPH: the approximation is valid as the number of samples in the kernel support goes to infinity, making the discretization of the integral exact, and as the kernel support goes to zero, making the convolution with the kernel function an exact identity\autocite*{sph-lucy-77}. It is sometimes noted that SPH can not guarantee 0-th order consistency for arbitrary samplings, however 0-th and 1st order consistency are in fact achieved if the conditions\autocite{tutorial}:
\begin{align}\label{eq:sph-consistency-conditions}
  \sum_j \frac{m_j}{\rho_j} W_{ij}=1 &  & \sum_j \frac{m_j}{\rho_j} (\vek{x}_j-\vek{x}_i)W_{ij}=1
\end{align}
hold, which can be enforced if desired by a normalization and a matrix inversion respectively \autocite*{price-2012}, although this is often not required for plausible results.

Further, note that if spherical symmetry is not enforced, a kernel may be constructed that linearly interpolates quantities along the Cartesian coordinate axes, compact to not just a sphere but a box within that sphere, and that this kernel may be evaluated on a regular grid, yielding the finite difference method. Whether SPH is therefore a generalization of grid-based methods or if the lack of the symmetry condition reduces the definition of 'SPH' to meaninglessness is a purely taxonomic question, but it underlines the expressivity of the SPH framework.

\horizontalspacer

A very typical choice for a kernel function is one that is similar to a Gaussian distribution in shape but has compact support, as demanded above. There are a few intuitions as to why a Gaussian-like kernel is a very natural choice for this problem. From the perspective of signal theory, it is common\autocite*{gauss-convolution-survey} and natural to apply a Gaussian filter to a signal in order to smoothen it and reduce high-frequency noise, allowing for better interpolation. The Gaussian is special in the sense that it is one of the eigenfunctions of the Fourier transform, yielding a Gaussian again when transformed\autocite*{gauss-eigenfunction}. More specifically, an isotropic (spherically symmetric) Gaussian filter can be thought of as the optimal way to filter a signal in many regards:
\begin{itemize}
  \item it does not overshoot when approximating step functions, being the unique function of a \cite[useful class of functions]{gauss-unique-preserve-local-extrema} that does not create or change local extrema\autocite*{gauss-convolution-survey}
  \item it does not create new zero-crossings in the second derivative\autocite*{gauss-convolution-survey}, which is crucial for fluid dynamics where zero-crossings of Laplacians are of interest (e.g. the pressure Poisson equation)
  \item it has optimal locality in space and frequency, minimizing the Heisenberg-Weyl inequality\autocite*{gauss-convolution-survey}. Intuitively, spatial locality has the benefit that the smoothed signal swiftly follows the original signal with minimal delay and high fidelity, while frequency locality means that the result is optimally smooth, since the Gaussian does not extend to higher frequencies and implements a stricter low-pass filter.
\end{itemize}

The last property is an interesting connection to the uncertainty principle, which is the same inequality but typically applied to momentum and locations in physics: the product of variances of a function in the spatial and frequency domains has a lower bound, which results in uncertainty when measuring in either domain, and the lowest bound is reached only by a Gaussian distribution.\\

Another perspective on the usefulness of the Gaussian and SPH in general is given by a probabilistic perspective on the problem. Interestingly, the original authors of SPH independently derive it from a stochastic point of view\autocite*{sph-lucy-77}\autocite*{sph-monaghan-gingold-77}, both groups even referencing the same book on Monte Carlo techniques\autocite*{hammersley-monte-carlo}.

Suppose fluid samples representing equal masses are independently sampled from a distribution proportional to the mass density of a fluid of homogeneous density. It then holds that the mass density can be approximated by counting the number of samples within some volume $\mathcal{V}$ around a point of interest $\vek{x}$ and normalizing the result\autocite{smoothed-density-parzen-62}. It is equally valid to define certain compactly supported kernel functions to weigh the samples by and sum those weighted contributions instead of simply counting the samples in $\mathcal{V}$ with an indicator function, such that the weight functions potentially smooth out the approximated field\autocite*{smoothed-density-parzen-62}. The resulting integral\autocite*{sph-monaghan-gingold-77} $\rho_{est}(\vek{x}) = \int_{\vek{x}_j\in\mathcal{V}} W(\vek{x}-\vek{x_j})\rho(\vek{x}_j)\,d\vek{x}_j$ can then be approximated by a Monte-Carlo estimator over discrete samples $\vek{x}_j$ drawn from a distribution $\rho' \propto \rho$, yielding the SPH method\autocite*{sph-monaghan-gingold-77}. Again, it is natural to model the kernel $W$ to a Gaussian by invoking the central limit theorem to argue that the measured number of samples in the volume, and by proxy the estimated density, is distributed normally around the true density as this process is repeated.

\horizontalspacer

A very commonly used kernel that mimics the Gaussian in shape but has compact support and
is fast to evaluate by virtue of being a polynomial is the \emphasis{cubic spline kernel} or $M_4$ Schoenberg B-spline\autocite*{price-2012}\autocite*{teschner-lecture}:
\begin{align}
  \label{eq:kernel-function}
  W(\vek{x}, \hbar)        & = \frac{\alpha}{4h^d}\begin{cases}
                                                    (2-q)^3 -4(1-q)^3 & 0\leq q<1 \\
                                                    (2-q)^3           & 1\leq q<2 \\
                                                    0                 & q \geq 2
                                                  \end{cases}                                   \\\label{eq:kernel-function-nabla}
  \nabla W(\vek{x}, \hbar) & = \frac{\alpha}{4h^d} \frac{\vek{x}}{\dist{\vek{x}}h}\begin{cases}
                                                                                    -3(2-q)^2+12(1-q)^2 & 0\leq q<1 \\
                                                                                    -3(2-q)^2           & 1\leq q<2 \\
                                                                                    0                   & q \geq 2
                                                                                  \end{cases}
\end{align}
where $q:=\frac{\dist{\vek{x}}}{h}$ is the distance normalized to a particle spacing $h$, it holds that $\hbar=2h$, $d$ is the number of dimensions and $\alpha$ is a dimensionality-dependent constant which is $\frac{2}{3}$ for 1D, $\frac{10}{7 \pi}$ for 2D and $\frac{1}{\pi}$ for 3D\autocite*{price-2012}. The kernel can also be written branchlessly (and implemented as such) as\autocite*{teschner-lecture}:
\begin{align}
  W(\vek{x}, \hbar)        & = \alpha \left[\max\left(0\,,\, 2-q\right)^3 -4\max\left(0\,,\, 1-q\right)^3 \right]                                    \\
  \nabla W(\vek{x}, \hbar) & = \alpha \frac{\vek{x}}{\dist{\vek{x}}h} \left[-3\max\left(0\,,\, 2-q\right)^2 +12\max\left(0\,,\, 1-q\right)^2 \right]
\end{align}

This kernel function and its first derivative are illustrated in \autoref{fig:kernel-function}.

\begin{figure}[b]
  \centering
  \begin{asy}
    import graph;
    size(400,150,IgnoreAspect);
    real h=1.0;
    real pi=3.1415926535;
    real alpha = 1.0/(6.0*h);

    real w(real d) {
        real q = abs(d);
        if(0.0<=q && q<1.0){
            return alpha*((2.0-q)*(2.0-q)*(2.0-q) -4.0*(1.0-q)*(1.0-q)*(1.0-q));
          }
        if(1.0<=q && q<2.0){
            return alpha*((2.0-q)*(2.0-q)*(2.0-q));
          }
        return 0.0;
      }

    real dw(real d) {
        real q = abs(d);
        if(0.0<=q && q<1.0){
            return sgn(d)*alpha/h*(-3.0*(2.0-q)*(2.0-q) +12.0*(1.0-q)*(1.0-q));
          }
        if(1.0<=q && q<2.0){
            return sgn(d)*alpha/h*(-3.0*(2.0-q)*(2.0-q));
          }
        return 0.0;
      }

    // real gauss(real d){
        //     real sig = 1.0;
        //     return 0.5*(1.0/sig*sqrt(2.0*pi)) * exp(-0.5*d*d/(sig*sig));
        //   }
    // draw(graph(gauss,-2,2),green,"$\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$");

    draw(graph(w,-2,2),heavyred,"$W(\vek{x},\hbar)$");
    draw(graph(dw,-2,2),heavyblue,"$||{\nabla W(\vek{x}, \hbar)}||$");

    xaxis("$\frac{\dist{\vek{x}}}{h}$",Bottom,RightTicks);
    yaxis("",Left,LeftTicks(trailingzero));


    add(legend(),point(E),2E,UnFill);
  \end{asy}
  \caption{The kernel function in 1D and the magnitude of its derivative are shown with respect to the length of $\vek{x}$ normalized by the particle spacing $h$. It can be seen that the kernel support for this function is $\hbar = 2h$. $W$ can also be written as parameterized by a scalar distance and is therefore spherically symmetric around the origin, while $\nabla W$ depends on the direction of $\vek{x}$ as seen in \autoref{eq:kernel-function-nabla} and is antisymmetric.}
  \label{fig:kernel-function}
\end{figure}


% Seeing as the $\delta$-distribution can be thought of as the limit of a Gaussian as it approaches zero variance, it might be approximated by a function similar in shape to a Gaussian, but with compact support as \autoref{eq:conv-identity} demands. The limited support has the additional benefit of making the computation of the convolution in linear time possible, which is crucial for efficiency.


% Suppose a volume $\mathcal{V}$ is filled with samples $\mathcal{S}$ randomly distributed according to some probability density. Were the underlying density unknown, it would be reasonable to approximate it by counting the number of samples within a spherical subvolume around each location $\vek{x}$ of interest and normalizing by the total number of samples\autocite{smoothed-density-parzen-62}. This could be implemented by summing over the samples, weighing each with a normalized \emphasis{kernel function} $W(d)$ of compact support, where $d$ is the distance between a sample $\vek{x}'\in\mathcal{V}$ and the sphere's centre $\vek{x}$. The estimated density $\rho_{est}$ would be\autocite*{sph-monaghan-gingold-77}:
% \begin{equation}
%   \rho_{est}(\vek{x}) = \int_\mathcal{V} W(\dist{\vek{x} - \vek{x}'}) \rho(\vek{x}')\,dV
% \end{equation}

% While the true density $\rho$ might be unknown, a Monte Carlo estimation of the integral can still be constructed, since any number $N$ of samples $\vek{x}_i$ is distributed proportionally to the density\autocite*{sph-monaghan-gingold-77}:
% \begin{equation}
%   \rho_N(\vek{x}) = \frac{\int_\mathcal{V} \rho(\vek{x}_i)\,dV}{N} \sum_{i=1}^N W(\dist{\vek{x} - \vek{x}_i})
% \end{equation}


% This can be written as:
% \begin{equation}
%   \rho_{est} = \int_{\vek{x}_i\in\mathcal{S}} W(\abs{\vek{x}-\vek{x}_i})\,d\vek{x}_i
% \end{equation}
% were $W$ is a \emphasis{kernel function} that is normalized to $\int_{\mathcal{V}} W(\abs{\vek{x}-\vek{x}_i})\,d\vek{x}_i = 1$

% Interestingly, the original authors independently derive SPH from a stochastic point of view, both even referencing the same book on Monte Carlo techniques\autocite*{hammersley-monte-carlo}. Consider a set of points that are randomly distributed in a volume according to some probability density function. If this density function was to be approximated, it would be reasonable to count the number of samples within a spherical volume surrounding any point and normalize the result to obtain a Monte Carlo estimate of the continuous density function by proxy\autocite*{smoothed-density-parzen-62}. Since the underlying density function is smooth, but the result of counting samples is not, it is reasonable to weigh each point by a possibly smooth \emphasis{kernel function} $W(d)$ in the distance $d$ to the centre of the sphere in question, which must preserve the consistency of the estimator - counting discrete samples in the sphere corresponds to using a step function in this case. If the kernel is normalized, meaning it satisfies $\int_\mathcal{V}W(\abs{\vek{x}_i - \vek{x}}) \,d\vek{x}_i = 1$, then the integral:
% \begin{equation}

% \end{equation}


% Another, more reasonable kernel function might be a Gaussian kernel, since the density estimate is smooth in all directions, even though the samples being interpolated are discrete. Both of these kernels and many others lead to the correct result as the number of samples within the range of the possibly compact kernel and the total number of samples tends to infinity\autocite*{smoothed-density-parzen-62}.

% More formally:

